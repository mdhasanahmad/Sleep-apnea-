{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13368809,"sourceType":"datasetVersion","datasetId":8480929}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:48:51.523079Z","iopub.execute_input":"2025-11-23T11:48:51.523316Z","iopub.status.idle":"2025-11-23T11:48:51.528178Z","shell.execute_reply.started":"2025-11-23T11:48:51.523289Z","shell.execute_reply":"2025-11-23T11:48:51.527560Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install wfdb\n!pip install neurokit2\n!pip install nolds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:48:51.529369Z","iopub.execute_input":"2025-11-23T11:48:51.529627Z","iopub.status.idle":"2025-11-23T11:49:04.326400Z","shell.execute_reply.started":"2025-11-23T11:48:51.529610Z","shell.execute_reply":"2025-11-23T11:49:04.325541Z"}},"outputs":[{"name":"stdout","text":"Collecting wfdb\n  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.13.2)\nRequirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.10.0)\nRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.7.2)\nRequirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.26.4)\nRequirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.2.3)\nRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.5)\nRequirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.15.3)\nRequirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.10.5)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.4->wfdb) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nDownloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wfdb\nSuccessfully installed wfdb-4.3.0\nCollecting neurokit2\n  Downloading neurokit2-0.2.12-py2.py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from neurokit2) (2.32.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from neurokit2) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from neurokit2) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from neurokit2) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from neurokit2) (1.2.2)\nRequirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from neurokit2) (3.7.2)\nRequirement already satisfied: PyWavelets>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from neurokit2) (1.8.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->neurokit2) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->neurokit2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->neurokit2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->neurokit2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->neurokit2) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->neurokit2) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->neurokit2) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->neurokit2) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.6.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->neurokit2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->neurokit2) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (2025.10.5)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->neurokit2) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->neurokit2) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->neurokit2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->neurokit2) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->neurokit2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->neurokit2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->neurokit2) (2024.2.0)\nDownloading neurokit2-0.2.12-py2.py3-none-any.whl (708 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.4/708.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: neurokit2\nSuccessfully installed neurokit2-0.2.12\nCollecting nolds\n  Downloading nolds-0.6.2-py2.py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: numpy<3.0,>1.0 in /usr/local/lib/python3.11/dist-packages (from nolds) (1.26.4)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from nolds) (1.0.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nolds) (75.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>1.0->nolds) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>1.0->nolds) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>1.0->nolds) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>1.0->nolds) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>1.0->nolds) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>1.0->nolds) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>1.0->nolds) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>1.0->nolds) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>1.0->nolds) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>1.0->nolds) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>1.0->nolds) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>1.0->nolds) (2024.2.0)\nDownloading nolds-0.6.2-py2.py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: nolds\nSuccessfully installed nolds-0.6.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# apnea_single_split_eval_highacc_with_features.py\n# Pipeline: sequence + tabular features, ensemble feature selection\n# Labeling: MIDPOINT RULE (middle minute decides label)\n\nimport os\nimport wfdb\nimport numpy as np\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom scipy.signal import butter, filtfilt, find_peaks, welch\nfrom scipy.interpolate import interp1d\nfrom scipy.stats import skew, kurtosis, entropy\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Optional libs\ntry:\n    import librosa\n    _HAS_LIBROSA = True\nexcept Exception:\n    _HAS_LIBROSA = False\ntry:\n    import pywt\n    _HAS_PYWT = True\nexcept Exception:\n    _HAS_PYWT = False\n\n# ---------------------------\n# Config\n# ---------------------------\nDATASET_PATH = \"/kaggle/input/apnea-new-dataset/apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0\"\nORIG_FS = 100\nWIN_MIN = 7\nSTRIDE_MIN = 1\nWIN_SIZE = ORIG_FS * 60 * WIN_MIN\nSTEP = ORIG_FS * 60 * STRIDE_MIN\nSEQ_LEN = 300\nBATCH_SIZE = 64\nEPOCHS = 50\nLR = 2e-4\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSEED = 42\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\nTARGET_PER_CLASS = 7071\nTEST_SIZE = 0.2\nTOP_K_FEATURES = 40  # selected via ensemble method\n\n# ---------------------------\n# Preprocessing helpers\n# ---------------------------\ndef bandpass(sig, fs=ORIG_FS, low=0.5, high=45.0, order=5):\n    nyq = 0.5 * fs\n    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n    return filtfilt(b, a, sig)\n\ndef detect_rpeaks(sig, fs=ORIG_FS):\n    sig = sig - np.median(sig)\n    th = np.median(np.abs(sig)) + 0.5 * np.std(sig)\n    min_dist = int(0.35 * fs)\n    peaks, _ = find_peaks(np.abs(sig), height=th, distance=min_dist)\n    return peaks\n\ndef build_rri_ra(segment, fs=ORIG_FS):\n    peaks = detect_rpeaks(segment, fs)\n    if len(peaks) < 2:\n        return None\n    rri = np.diff(peaks) * 1000 / fs\n    ra = segment[peaks[:-1]]\n    return rri.astype(np.float32), ra.astype(np.float32)\n\ndef resample_seq(seq, target_len=SEQ_LEN):\n    if len(seq) < 2:\n        return np.zeros(target_len, dtype=np.float32)\n    x_old = np.linspace(0, 1, len(seq))\n    x_new = np.linspace(0, 1, target_len)\n    f = interp1d(x_old, seq, kind=\"linear\", fill_value=\"extrapolate\")\n    return f(x_new).astype(np.float32)\n\ndef augment_signal(sig):\n    sig = sig + np.random.normal(0, 0.01 * np.std(sig), sig.shape)\n    if random.random() < 0.5:\n        sig = sig * (0.9 + 0.2 * np.random.rand())\n    return sig\n\n# ---------------------------\n# Feature extraction\n# ---------------------------\ndef time_domain_features(x):\n    feats = []\n    if len(x) == 0:\n        return [0.0]*10\n    feats.append(np.mean(x))\n    feats.append(np.std(x))\n    feats.append(np.median(x))\n    feats.append(np.min(x))\n    feats.append(np.max(x))\n    feats.append(np.ptp(x))\n    feats.append(np.sqrt(np.mean(x**2)))\n    feats.append(skew(x) if len(x) > 2 else 0.0)\n    feats.append(kurtosis(x) if len(x) > 2 else 0.0)\n    p, _ = np.histogram(x, bins=10, density=True)\n    p = p[p > 0]\n    feats.append(entropy(p) if p.size > 0 else 0.0)\n    return feats\n\ndef frequency_domain_features(x, fs=ORIG_FS):\n    if len(x) < 2:\n        return [0.0]*8\n    f, Pxx = welch(x, fs=fs, nperseg=min(len(x), 256))\n    Psum = np.sum(Pxx) + 1e-12\n    centroid = np.sum(f * Pxx) / Psum\n    bw = np.sqrt(np.sum(((f - centroid)**2) * Pxx) / Psum)\n    dom = f[np.argmax(Pxx)]\n    p = Pxx / Psum\n    spec_ent = entropy(p + 1e-12)\n    low_band = np.sum(Pxx[(f >= 0.5) & (f < 4)])\n    mid_band = np.sum(Pxx[(f >= 4) & (f < 15)])\n    high_band = np.sum(Pxx[(f >= 15) & (f <= fs/2)])\n    total = low_band + mid_band + high_band + 1e-12\n    return [centroid, bw, dom, spec_ent, low_band/total, mid_band/total, high_band/total, np.log(total+1e-12)]\n\ndef cepstral_features(x, fs=ORIG_FS, n_mfcc=13):\n    if len(x) < 2:\n        return [0.0]*n_mfcc\n    if _HAS_LIBROSA:\n        try:\n            mfccs = librosa.feature.mfcc(y=x.astype(float), sr=fs, n_mfcc=n_mfcc)\n            return np.mean(mfccs, axis=1).tolist()\n        except Exception:\n            pass\n    X = np.fft.rfft(x * np.hanning(len(x)))\n    log_spec = np.log(np.abs(X) + 1e-12)\n    cep = np.real(np.fft.ifft(np.concatenate([log_spec, log_spec[::-1]])))[:n_mfcc]\n    cep = np.pad(cep, (0, max(0, n_mfcc - len(cep))), 'constant')[:n_mfcc]\n    return cep.tolist()\n\ndef dwt_features(x, level=3):\n    if len(x) < 2:\n        return [0.0]*(level+1)\n    if _HAS_PYWT:\n        try:\n            coeffs = pywt.wavedec(x, \"db4\", level=level)\n            energies = [np.log(np.sum(c**2) + 1e-12) for c in coeffs]\n            return energies[:(level+1)]\n        except Exception:\n            pass\n    f, Pxx = welch(x, fs=ORIG_FS, nperseg=min(len(x), 256))\n    bands = np.array_split(Pxx, level+1)\n    return [np.log(np.sum(b)+1e-12) for b in bands]\n\ndef extract_tabular_features(window, fs=ORIG_FS):\n    feats = []\n    feats += time_domain_features(window)\n    feats += frequency_domain_features(window, fs)\n    feats += cepstral_features(window, fs, n_mfcc=8)\n    feats += dwt_features(window, level=3)\n    rri_ra = build_rri_ra(window, fs)\n    if rri_ra is None:\n        feats += [0.0]*10\n    else:\n        rri, ra = rri_ra\n        feats += time_domain_features(rri)\n        feats += time_domain_features(ra)\n    return np.array(feats, dtype=np.float32)\n\n# ----------------------------------------------------------\n#                INDEX BUILDER (MIDPOINT RULE)\n# ----------------------------------------------------------\ndef build_index(records, win_min=WIN_MIN):\n    idx = []\n    for rec in records:\n        try:\n            ann = wfdb.rdann(os.path.join(DATASET_PATH, rec), \"apn\")\n            labels = ann.symbol\n            total_len = wfdb.rdrecord(os.path.join(DATASET_PATH, rec)).p_signal.shape[0]\n        except Exception:\n            continue\n\n        starts = range(0, total_len - WIN_SIZE + 1, STEP)\n\n        for s in starts:\n            start_min = s // (ORIG_FS * 60)\n\n            # ---------- MIDPOINT RULE ----------\n            mid_min = start_min + win_min // 2+1\n\n            if mid_min >= len(labels):\n                continue\n\n            if labels[mid_min] == \"A\":\n                lab = 1\n            else:\n                lab = 0\n            # ------------------------------------\n\n            idx.append((rec, s, lab))\n\n    return idx\n\n# ---------------------------\n# Dataset\n# ---------------------------\nclass ApneaDatasetWithFeatures(Dataset):\n    def __init__(self, index, feats_list, seq_len=SEQ_LEN, augment=False):\n        self.index = index\n        self.feats_list = feats_list\n        self.seq_len = seq_len\n        self.augment = augment\n\n    def __len__(self): return len(self.index)\n\n    def __getitem__(self, idx):\n        rec, s, label = self.index[idx]\n        sig = wfdb.rdrecord(os.path.join(DATASET_PATH, rec)).p_signal[:, 0].astype(np.float32)\n        window = sig[s:s + WIN_SIZE]\n        if self.augment:\n            window = augment_signal(window)\n        window = bandpass(window)\n        result = build_rri_ra(window)\n        if result is None:\n            feat_seq = np.zeros((self.seq_len, 2), dtype=np.float32)\n        else:\n            rri, ra = result\n            rri = (rri - np.mean(rri)) / (np.std(rri) + 1e-6)\n            ra = (ra - np.mean(ra)) / (np.std(ra) + 1e-6)\n            feat_seq = np.stack([resample_seq(rri, self.seq_len), resample_seq(ra, self.seq_len)], axis=1)\n        tab_feat = self.feats_list[idx]\n        return torch.from_numpy(feat_seq), torch.from_numpy(tab_feat), torch.tensor(label, dtype=torch.long)\n\n# ---------------------------\n# Model\n# ---------------------------\nclass EnhancedCNNBiLSTMTransformerWithTabs(nn.Module):\n    def __init__(self, in_ch=2, hidden=128, extra_feat_dim=0):\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv1d(in_ch, 128, 7, padding=3), nn.BatchNorm1d(128), nn.ReLU(),\n            nn.Conv1d(128, 256, 5, padding=2), nn.BatchNorm1d(256), nn.ReLU(),\n            nn.Conv1d(256, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n            nn.AdaptiveAvgPool1d(100)\n        )\n        self.lstm = nn.LSTM(256, hidden, batch_first=True, bidirectional=True, dropout=0.3)\n        proj_dim = 256\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=proj_dim, nhead=8, dim_feedforward=512,\n            dropout=0.3, batch_first=True, norm_first=True\n        )\n        self.trans = nn.TransformerEncoder(encoder_layer, num_layers=4)\n        self.extra_feat_dim = extra_feat_dim\n        if extra_feat_dim > 0:\n            self.tab_proj = nn.Sequential(\n                nn.Linear(extra_feat_dim, 128), nn.LayerNorm(128), nn.ReLU(), nn.Dropout(0.2)\n            )\n            fc_input_dim = proj_dim + 128\n        else:\n            self.tab_proj = None\n            fc_input_dim = proj_dim\n        self.fc = nn.Sequential(\n            nn.Linear(fc_input_dim, 128), nn.LayerNorm(128), nn.ReLU(), nn.Dropout(0.5),\n            nn.Linear(128, 2)\n        )\n\n    def forward(self, x, tab=None):\n        x = x.permute(0, 2, 1)\n        x = self.cnn(x)\n        x = x.permute(0, 2, 1)\n        _, (h, _) = self.lstm(x)\n        feat = torch.cat([h[-2], h[-1]], dim=1).unsqueeze(1)\n        feat = self.trans(feat).mean(dim=1)\n        if self.extra_feat_dim > 0 and tab is not None:\n            t = self.tab_proj(tab)\n            combined = torch.cat([feat, t], dim=1)\n        else:\n            combined = feat\n        return self.fc(combined)\n\n# ---------------------------\n# Ensemble feature selection\n# ---------------------------\ndef ensemble_feature_selection(X_train, y_train, K=TOP_K_FEATURES, random_state=SEED):\n    f_vals, _ = f_classif(X_train, y_train)\n    mi_vals = mutual_info_classif(X_train, y_train, random_state=random_state)\n    rf = RandomForestClassifier(n_estimators=200, random_state=random_state, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    rf_imp = rf.feature_importances_\n    def norm(x): return (x - np.min(x)) / (np.ptp(x) + 1e-12)\n    agg = (norm(f_vals) + norm(mi_vals) + norm(rf_imp)) / 3.0\n    top_idx = np.argsort(agg)[::-1][:K]\n    return top_idx, agg[top_idx]\n\n# ---------------------------\n# Training utilities\n# ---------------------------\ndef train_epoch_with_tabs(model, loader, opt, crit):\n    model.train()\n    total = 0\n    for X, tab, y in tqdm(loader, desc=\"Train\"):\n        X, tab, y = X.to(DEVICE), tab.to(DEVICE), y.to(DEVICE)\n        opt.zero_grad()\n        out = model(X, tab)\n        loss = crit(out, y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        opt.step()\n        total += loss.item()\n    return total / max(1, len(loader))\n\ndef evaluate_with_tabs(model, loader):\n    model.eval()\n    preds, gts = [], []\n    with torch.no_grad():\n        for X, tab, y in loader:\n            X = X.to(DEVICE)\n            tab = tab.to(DEVICE)\n            out = model(X, tab)\n            preds += out.argmax(1).cpu().tolist()\n            gts += y.tolist()\n    return np.array(gts), np.array(preds)\n\n# ---------------------------\n# Main\n# ---------------------------\nif __name__ == \"__main__\":\n    records = [f\"a{str(i).zfill(2)}\" for i in range(1, 20 + 1)]\n    print(\"Building index using MIDPOINT labeling rule...\")\n    index = build_index(records)\n    if len(index) == 0:\n        raise RuntimeError(\"No index entries found. Check path or timings.\")\n\n    pos = [x for x in index if x[2] == 1]\n    neg = [x for x in index if x[2] == 0]\n\n    def sample_fixed(lst, n):\n        return random.sample(lst, n) if len(lst) >= n else lst + random.choices(lst, k=n - len(lst))\n\n    pos, neg = sample_fixed(pos, TARGET_PER_CLASS), sample_fixed(neg, TARGET_PER_CLASS)\n    balanced = pos + neg\n    random.shuffle(balanced)\n    labels = np.array([x[2] for x in balanced])\n\n    print(\"Extracting tabular features...\")\n    all_feats = []\n    for (rec, s, lab) in tqdm(balanced):\n        try:\n            sig = wfdb.rdrecord(os.path.join(DATASET_PATH, rec)).p_signal[:, 0].astype(np.float32)\n            win = bandpass(sig[s:s + WIN_SIZE])\n            feat_vec = extract_tabular_features(win, ORIG_FS)\n        except Exception:\n            feat_vec = np.zeros(50, dtype=np.float32)\n        all_feats.append(feat_vec)\n\n    max_len = max([len(f) for f in all_feats])\n    feat_mat = np.zeros((len(all_feats), max_len), dtype=np.float32)\n    for i, f in enumerate(all_feats):\n        feat_mat[i, :len(f)] = f\n\n    imp = SimpleImputer(strategy=\"median\")\n    feat_mat = imp.fit_transform(feat_mat)\n    scaler = StandardScaler()\n    feat_mat = scaler.fit_transform(feat_mat)\n\n    idx_all = np.arange(len(balanced))\n    train_idx, test_idx = train_test_split(idx_all, test_size=TEST_SIZE, stratify=labels, random_state=SEED)\n\n    X_train = feat_mat[train_idx]\n    y_train = labels[train_idx]\n    X_test = feat_mat[test_idx]\n    y_test = labels[test_idx]\n\n    top_idx, _ = ensemble_feature_selection(X_train, y_train, K=TOP_K_FEATURES)\n    X_train_sel = X_train[:, top_idx]\n    X_test_sel = X_test[:, top_idx]\n\n    sel_all = feat_mat[:, top_idx].astype(np.float32)\n\n    train_index = [balanced[i] for i in train_idx]\n    test_index = [balanced[i] for i in test_idx]\n    train_feats = [sel_all[i] for i in train_idx]\n    test_feats = [sel_all[i] for i in test_idx]\n\n    train_ds = ApneaDatasetWithFeatures(train_index, np.array(train_feats), augment=True)\n    test_ds = ApneaDatasetWithFeatures(test_index, np.array(test_feats), augment=False)\n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=2, pin_memory=True)\n\n    model = EnhancedCNNBiLSTMTransformerWithTabs(extra_feat_dim=TOP_K_FEATURES).to(DEVICE)\n    class_counts = np.bincount(labels)\n    class_counts = np.where(class_counts == 0, 1, class_counts)\n    weights = torch.tensor([1/class_counts[0], 1/class_counts[1]], dtype=torch.float32).to(DEVICE)\n    crit = nn.CrossEntropyLoss(weight=weights)\n    opt = torch.optim.AdamW(model.parameters(), lr=LR)\n\n    for epoch in range(1, EPOCHS+1):\n        loss = train_epoch_with_tabs(model, train_loader, opt, crit)\n        print(f\"Epoch {epoch}/{EPOCHS} - Loss: {loss:.4f}\")\n\n    y_true, y_pred = evaluate_with_tabs(model, test_loader)\n    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n    print(\"F1:\", f1_score(y_true, y_pred))\n    print(\"Kappa:\", cohen_kappa_score(y_true, y_pred))\n    print(classification_report(y_true, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:51:44.245665Z","iopub.execute_input":"2025-11-23T11:51:44.246281Z","iopub.status.idle":"2025-11-23T14:10:55.390657Z","shell.execute_reply.started":"2025-11-23T11:51:44.246255Z","shell.execute_reply":"2025-11-23T14:10:55.389641Z"}},"outputs":[{"name":"stdout","text":"Building index using MIDPOINT labeling rule...\nExtracting tabular features...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14142/14142 [10:02<00:00, 23.48it/s]\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n  warnings.warn(\nTrain: 100%|██████████| 177/177 [02:30<00:00,  1.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50 - Loss: 0.5402\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50 - Loss: 0.3710\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:34<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/50 - Loss: 0.3173\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:31<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/50 - Loss: 0.2886\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/50 - Loss: 0.2672\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/50 - Loss: 0.2586\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:31<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/50 - Loss: 0.2375\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50 - Loss: 0.2223\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/50 - Loss: 0.2036\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/50 - Loss: 0.1890\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:34<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/50 - Loss: 0.1796\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:38<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/50 - Loss: 0.1638\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:30<00:00,  1.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/50 - Loss: 0.1566\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50 - Loss: 0.1465\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/50 - Loss: 0.1361\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:34<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/50 - Loss: 0.1204\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/50 - Loss: 0.1136\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/50 - Loss: 0.1050\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:31<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/50 - Loss: 0.0957\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/50 - Loss: 0.0983\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:34<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/50 - Loss: 0.0885\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/50 - Loss: 0.0812\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:31<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/50 - Loss: 0.0705\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/50 - Loss: 0.0712\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/50 - Loss: 0.0656\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:38<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/50 - Loss: 0.0654\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/50 - Loss: 0.0487\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28/50 - Loss: 0.0523\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/50 - Loss: 0.0401\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30/50 - Loss: 0.0529\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:34<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/50 - Loss: 0.0479\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:34<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32/50 - Loss: 0.0453\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33/50 - Loss: 0.0376\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:36<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34/50 - Loss: 0.0499\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:36<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35/50 - Loss: 0.0330\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:37<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36/50 - Loss: 0.0368\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:37<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37/50 - Loss: 0.0360\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38/50 - Loss: 0.0305\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:30<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39/50 - Loss: 0.0295\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40/50 - Loss: 0.0310\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41/50 - Loss: 0.0276\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:34<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42/50 - Loss: 0.0339\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43/50 - Loss: 0.0301\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44/50 - Loss: 0.0266\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:35<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45/50 - Loss: 0.0342\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46/50 - Loss: 0.0314\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:32<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47/50 - Loss: 0.0276\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:33<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48/50 - Loss: 0.0213\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:36<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49/50 - Loss: 0.0249\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 177/177 [02:37<00:00,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 50/50 - Loss: 0.0261\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.953340402969247\nF1: 0.9534555712270805\nKappa: 0.9066809808407978\n              precision    recall  f1-score   support\n\n           0       0.96      0.95      0.95      1415\n           1       0.95      0.96      0.95      1414\n\n    accuracy                           0.95      2829\n   macro avg       0.95      0.95      0.95      2829\nweighted avg       0.95      0.95      0.95      2829\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}